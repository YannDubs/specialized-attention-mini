{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spattn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanndubois/venvs/spattn/lib/python3.7/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/Users/yanndubois/venvs/spattn/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/yanndubois/venvs/spattn/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from spattn.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../machine-tasks/LookupTables/lookup-3bit/samples/sample1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=10\n",
    "train, dev, src, tgt, oneshot = get_train_dev(folder + \"train.tsv\",\n",
    "                                              folder + \"validation.tsv\",\n",
    "                                               max_len,\n",
    "                                                10000,\n",
    "                                                 10000, content_method=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanndubois/Desktop/GitHub/specialized-attention-mini/spattn/attention/KVQ.py:152: UserWarning: Using value_size == 64 instead of 100 bcause highway.\n",
      "  warnings.warn(\"Using value_size == {} instead of {} bcause highway.\".format(embedding_size, self.output_size))\n"
     ]
    }
   ],
   "source": [
    "seq2seq = get_seq2seq_model(src, tgt, max_len, 1000, is_mlps=True, embedding_size=64, \n",
    "                            rnn_cell='gru', hidden_size=128, is_weight_norm=True, dropout_input_encoder=0.1, \n",
    "                            dropout_input_decoder=0.2, anneal_mid_dropout=0.3, anneal_mid_noise=0.4, is_highway=True, \n",
    "                            initial_highway=0.9, is_single_carry=True, is_additive_highway=True, \n",
    "                            is_add_all_controller=True, content_method='scalemult', is_content_attn=True, \n",
    "                            key_size=16, value_size=100, is_contained_kv=True, anneal_kq_dropout_output=0.5, \n",
    "                            anneal_kq_noise_output=0.6, is_position_attn=True, n_steps_prepare_pos=10, \n",
    "                            positioning_method='laplace', is_posrnn=True, rate_init_help=0.7, anneal_min_sigma=0.8, \n",
    "                            is_bb_bias=True, regularizations=['is_reg_clamp_mu', 'is_l0_bb_weights'], \n",
    "                            lp_reg_weights=2, is_clamp_weights=True, rate_start_round=0.9, anneal_temp_round=0.85, \n",
    "                            rounder_weights='concrete', rounder_mu='stochastic', mode_attn_mix='normalized_pos_conf', \n",
    "                            rate_attmix_wait=0.75, default_pos_perc=0.65, rounder_perc='concrete', is_dev_mode=True, \n",
    "                            is_viz_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (input_dropout): Dropout(p=0.1)\n",
       "    (embedding): Embedding(19, 64)\n",
       "    (controller): GRU(64, 128, batch_first=True)\n",
       "    (key_generator): KQGenerator(\n",
       "      input_size=128, output_size=16, is_contained_kv=True\n",
       "      (generator): MLP(\n",
       "        input_size=32, hidden_size=16, output_size=16\n",
       "        (mlp): Linear(in_features=32, out_features=16, bias=True)\n",
       "        (activation): ReLU()\n",
       "        (out): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (dropout_output): AnnealedDropout(initial_dropout=0.7, final_dropout=0.1, n_steps_interpolate=500, geometric)\n",
       "      (noise_output): AnnealedGaussianNoise(initial_sigma=0.2, final_sigma=0, n_steps_interpolate=600, linear)\n",
       "    )\n",
       "    (value_generator): ValueGenerator(\n",
       "      input_size=128, output_size=64, is_contained_kv=True, is_highway=True\n",
       "      (generator): MLP(\n",
       "        input_size=64, hidden_size=64, output_size=64\n",
       "        (mlp): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (activation): ReLU()\n",
       "        (out): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (highway): Highway(\n",
       "        output_size=64, initial_highway=0.9, is_additive_highway=True\n",
       "        (carrier): MLP(\n",
       "          input_size=64, hidden_size=16, output_size=1\n",
       "          (mlp): Linear(in_features=64, out_features=16, bias=True)\n",
       "          (activation): ReLU()\n",
       "          (out): Linear(in_features=16, out_features=1, bias=True)\n",
       "        )\n",
       "        (carry_to_prob): ProbabilityConverter(min_p=0.001, activation=sigmoid, initial_probability=0.9)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (input_dropout): Dropout(p=0.2)\n",
       "    (embedding): Embedding(12, 64)\n",
       "    (controller): GRU(139, 128, batch_first=True)\n",
       "    (query_generator): KQGenerator(\n",
       "      input_size=128, output_size=16, is_contained_kv=True\n",
       "      (generator): MLP(\n",
       "        input_size=32, hidden_size=16, output_size=16\n",
       "        (mlp): Linear(in_features=32, out_features=16, bias=True)\n",
       "        (activation): ReLU()\n",
       "        (out): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (dropout_output): AnnealedDropout(initial_dropout=0.7, final_dropout=0.1, n_steps_interpolate=500, geometric)\n",
       "      (noise_output): AnnealedGaussianNoise(initial_sigma=0.2, final_sigma=0, n_steps_interpolate=600, linear)\n",
       "    )\n",
       "    (content_attention): ContentAttention(\n",
       "      (method): MultiplicativeAttn(\n",
       "        (linear): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (scaled_dot): DotAttn(is_scale=True)\n",
       "      )\n",
       "      (maxlogit_to_conf): ProbabilityConverter(min_p=0.001, activation=sigmoid, is_temperature=True, is_bias=True, initial_temperature=0.1)\n",
       "    )\n",
       "    (position_attention): PositionAttention(\n",
       "      initial_sigma=5.0, final_sigma=0.82, n_steps_interpolate=10, linear, regularizations=['is_reg_clamp_mu', 'is_l0_bb_weights'], positioning_method=laplace\n",
       "      (rnn): GRU(137, 32, batch_first=True)\n",
       "      (mu_weights_generator): Linear(in_features=32, out_features=6, bias=True)\n",
       "      (sigma_generator): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (rounder_weights): ConcreteRounding(start_step=900, initial_temperature=1, final_temperature=0.5, n_steps_interpolate=850, linear)\n",
       "      (rounder_mu): StochasticRounding(start_step=900)\n",
       "      (linear_l0_weights): L0Gates(\n",
       "        input_size=32, output_size=6, is_at_least_1=True\n",
       "        (gate_generator): Linear(in_features=32, out_features=6, bias=True)\n",
       "        (rounder): ConcreteRounding(start_step=0, initial_temperature=1, final_temperature=0.5, n_steps_interpolate=10, linear)\n",
       "      )\n",
       "    )\n",
       "    (mix_attention): AttentionMixer(\n",
       "      mode=normalized_pos_conf\n",
       "      (rounder_perc): ConcreteRounding(start_step=900, initial_temperature=1, final_temperature=0.5, n_steps_interpolate=850, linear)\n",
       "    )\n",
       "    (out): Linear(in_features=128, out_features=12, bias=True)\n",
       "  )\n",
       "  (mid_dropout): AnnealedDropout(initial_dropout=0.7, final_dropout=0.1, n_steps_interpolate=300, geometric)\n",
       "  (mid_noise): AnnealedGaussianNoise(initial_sigma=0.2, final_sigma=0, n_steps_interpolate=400, linear)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seq2seq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c3facfb0245c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seq2seq'"
     ]
    }
   ],
   "source": [
    "import seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_backend': <torch.nn.backends.thnn.THNNFunctionBackend at 0x11207b3c8>,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('encoder', EncoderRNN(\n",
       "                 (input_dropout): Dropout(p=0.1)\n",
       "                 (embedding): Embedding(19, 64)\n",
       "                 (controller): GRU(64, 128, batch_first=True)\n",
       "                 (key_generator): KQGenerator(\n",
       "                   input_size=128, output_size=16, is_contained_kv=True\n",
       "                   (generator): MLP(\n",
       "                     input_size=32, hidden_size=16, output_size=16\n",
       "                     (mlp): Linear(in_features=32, out_features=16, bias=True)\n",
       "                     (activation): ReLU()\n",
       "                     (out): Linear(in_features=16, out_features=16, bias=True)\n",
       "                   )\n",
       "                   (dropout_output): AnnealedDropout(initial_dropout=0.7, final_dropout=0.1, n_steps_interpolate=500, geometric)\n",
       "                   (noise_output): AnnealedGaussianNoise(initial_sigma=0.2, final_sigma=0, n_steps_interpolate=600, linear)\n",
       "                 )\n",
       "                 (value_generator): ValueGenerator(\n",
       "                   input_size=128, output_size=64, is_contained_kv=True, is_highway=True\n",
       "                   (generator): MLP(\n",
       "                     input_size=64, hidden_size=64, output_size=64\n",
       "                     (mlp): Linear(in_features=64, out_features=64, bias=True)\n",
       "                     (activation): ReLU()\n",
       "                     (out): Linear(in_features=64, out_features=64, bias=True)\n",
       "                   )\n",
       "                   (highway): Highway(\n",
       "                     output_size=64, initial_highway=0.9, is_additive_highway=True\n",
       "                     (carrier): MLP(\n",
       "                       input_size=64, hidden_size=16, output_size=1\n",
       "                       (mlp): Linear(in_features=64, out_features=16, bias=True)\n",
       "                       (activation): ReLU()\n",
       "                       (out): Linear(in_features=16, out_features=1, bias=True)\n",
       "                     )\n",
       "                     (carry_to_prob): ProbabilityConverter(min_p=0.001, activation=sigmoid, initial_probability=0.9)\n",
       "                   )\n",
       "                 )\n",
       "               )), ('decoder', DecoderRNN(\n",
       "                 (input_dropout): Dropout(p=0.2)\n",
       "                 (embedding): Embedding(12, 64)\n",
       "                 (controller): GRU(139, 128, batch_first=True)\n",
       "                 (query_generator): KQGenerator(\n",
       "                   input_size=128, output_size=16, is_contained_kv=True\n",
       "                   (generator): MLP(\n",
       "                     input_size=32, hidden_size=16, output_size=16\n",
       "                     (mlp): Linear(in_features=32, out_features=16, bias=True)\n",
       "                     (activation): ReLU()\n",
       "                     (out): Linear(in_features=16, out_features=16, bias=True)\n",
       "                   )\n",
       "                   (dropout_output): AnnealedDropout(initial_dropout=0.7, final_dropout=0.1, n_steps_interpolate=500, geometric)\n",
       "                   (noise_output): AnnealedGaussianNoise(initial_sigma=0.2, final_sigma=0, n_steps_interpolate=600, linear)\n",
       "                 )\n",
       "                 (content_attention): ContentAttention(\n",
       "                   (method): MultiplicativeAttn(\n",
       "                     (linear): Linear(in_features=16, out_features=16, bias=True)\n",
       "                     (scaled_dot): DotAttn(is_scale=True)\n",
       "                   )\n",
       "                   (maxlogit_to_conf): ProbabilityConverter(min_p=0.001, activation=sigmoid, is_temperature=True, is_bias=True, initial_temperature=0.1)\n",
       "                 )\n",
       "                 (position_attention): PositionAttention(\n",
       "                   initial_sigma=5.0, final_sigma=0.82, n_steps_interpolate=10, linear, regularizations=['is_reg_clamp_mu', 'is_l0_bb_weights'], positioning_method=laplace\n",
       "                   (rnn): GRU(137, 32, batch_first=True)\n",
       "                   (mu_weights_generator): Linear(in_features=32, out_features=6, bias=True)\n",
       "                   (sigma_generator): Linear(in_features=32, out_features=1, bias=True)\n",
       "                   (rounder_weights): ConcreteRounding(start_step=900, initial_temperature=1, final_temperature=0.5, n_steps_interpolate=850, linear)\n",
       "                   (rounder_mu): StochasticRounding(start_step=900)\n",
       "                   (linear_l0_weights): L0Gates(\n",
       "                     input_size=32, output_size=6, is_at_least_1=True\n",
       "                     (gate_generator): Linear(in_features=32, out_features=6, bias=True)\n",
       "                     (rounder): ConcreteRounding(start_step=0, initial_temperature=1, final_temperature=0.5, n_steps_interpolate=10, linear)\n",
       "                   )\n",
       "                 )\n",
       "                 (mix_attention): AttentionMixer(\n",
       "                   mode=normalized_pos_conf\n",
       "                   (rounder_perc): ConcreteRounding(start_step=900, initial_temperature=1, final_temperature=0.5, n_steps_interpolate=850, linear)\n",
       "                 )\n",
       "                 (out): Linear(in_features=128, out_features=12, bias=True)\n",
       "               )), ('mid_dropout',\n",
       "               AnnealedDropout(initial_dropout=0.7, final_dropout=0.1, n_steps_interpolate=300, geometric)), ('mid_noise',\n",
       "               AnnealedGaussianNoise(initial_sigma=0.2, final_sigma=0, n_steps_interpolate=400, linear))]),\n",
       " 'training': True,\n",
       " '_to_visualize': {},\n",
       " '_to_test': {},\n",
       " '_regularization_losses': {},\n",
       " 'is_dev_mode': True,\n",
       " 'is_update_mid_dropout': True,\n",
       " 'is_update_mid_noise': True,\n",
       " 'epoch': 0,\n",
       " 'training_step': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.__dict__.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
